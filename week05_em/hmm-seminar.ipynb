{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hidden Markov models for cracking codes**\n",
    "\n",
    "In this exercise you have to make a partially built HMM work and use it to solve some simple substitution ciphers. Plaintext data is provided in 'plaintext' directory. Encrypted data is in 'encrypted'. Some of the texts were originally English some of them were Russian; the sequences are also of different lengths. \n",
    "\n",
    "This homework is worth **15 points** and is due by the next class (**24th Oct.**), please submit the results of the **TASK 5** (a list of files and names of the author/work) to Anytask in the following format: 'filename author' where 'filename' is a file from \"encrypted/\\*_encrypted.txt\" and 'author' is a file from \"plaintext/\\*.txt\" (not including 'english.txt', 'russian.txt' or 'all.txt') which best matches the decrypted text.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities for loading data from file and converting characters to integers and back.\n",
    "import numpy as np\n",
    "    \n",
    "def get_char_to_int_mapping(path):\n",
    "    # Load data from path and get mapping from characters to integers and back.\n",
    "    characters = set()\n",
    "    for line in open(path, encoding='utf8'):\n",
    "        characters.update(set([c for c in line.strip()]))\n",
    "    char_to_int_mapping = dict([(char, i) for i, char in enumerate(sorted(list(characters)))])\n",
    "    int_to_char_mapping = [char for char, i in char_to_int_mapping.items()]\n",
    "    return char_to_int_mapping, int_to_char_mapping\n",
    "\n",
    "def load_sequences(path, char_to_int_mapping):\n",
    "    # Load data from path and map to integers using mapping.\n",
    "    return [[char_to_int_mapping[c] for c in line.strip()] for line in open(path, encoding='utf8')]\n",
    "\n",
    "def estimate_markov_model_from_sequences(sequences, num_states):\n",
    "    # Estimate a Markov model based on the sequences (integers) provided.\n",
    "\n",
    "    # pi[i] = Pr(s_0 = i)\n",
    "    pi_counts = np.zeros(num_states)\n",
    "\n",
    "    # A[i, j] = Pr(s_t = j | s_{t-1} = i)\n",
    "    A_counts = np.zeros((num_states, num_states))\n",
    "    move_out_count = np.zeros(num_states)\n",
    "\n",
    "    for n, sequence in enumerate(sequences):\n",
    "        for prev, nxt in zip(sequence[:-1], sequence[1:]):\n",
    "            A_counts[prev, nxt] += 1\n",
    "            pi_counts[prev] += 1\n",
    "        if len(sequence) > 0:\n",
    "            pi_counts[sequence[-1]] += 1\n",
    "            \n",
    "    pi = pi_counts / np.sum(pi_counts)\n",
    "    A = A_counts / np.sum(A_counts, axis=1)[:, None]\n",
    "    \n",
    "    return pi, A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 1**: Make the following block run by completing the method 'estimate_markov_model_from_sequences' above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 8, 5, 0, 19, 15, 14, 14, 5, 20, 19], [2, 25, 0, 23, 9, 12, 12, 9, 1, 13, 0, 19, 8, 1, 11, 5, 19, 16, 5, 1, 18, 5]]\n"
     ]
    }
   ],
   "source": [
    "# Some data to use.\n",
    "# plaintext = 'plaintext/english.txt'\n",
    "plaintext = 'plaintext/shakespeare.txt'\n",
    "# plaintext = 'plaintext/russian.txt'\n",
    "\n",
    "ciphertext = 'encrypted/1_encrypted.txt' # short sequences in english\n",
    "# ciphertext = 'encrypted/99_encrypted.txt' # longer sequences in russian\n",
    "\n",
    "# load a character to integer mapping and reverse                                                                                                         \n",
    "char_to_int_mapping, int_to_char_mapping = get_char_to_int_mapping(plaintext)\n",
    "\n",
    "# load sequences as ints                                                                                                                                  \n",
    "plaintext_sequences = load_sequences(plaintext, char_to_int_mapping)\n",
    "encrypted_sequences = load_sequences(ciphertext, char_to_int_mapping)\n",
    "print(plaintext_sequences[:2])\n",
    "# estimate a markov model over characters                                                                                                                 \n",
    "pi, A = estimate_markov_model_from_sequences(plaintext_sequences, len(char_to_int_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27,),\n",
       " (27, 27),\n",
       " 1.0,\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.shape, A.shape, pi.sum(), A.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a mostly implemented HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM():\n",
    "\n",
    "    def __init__(self, observations_to_char_mapping={}, states_to_char_mapping={}):\n",
    "        # Determine number of states and observation space. \n",
    "        self.num_states = len(states_to_char_mapping) # number of states = number of chars \n",
    "        self.num_outputs = len(observations_to_char_mapping) # number of outputs ?\n",
    "        self.states_to_char_mapping = states_to_char_mapping # get char from state\n",
    "        self.observations_to_char_mapping = observations_to_char_mapping # what is observations ??? \n",
    "       \n",
    "        # Random initialization\n",
    "        self.pi = np.random.rand(self.num_states).astype('float64') # init pi with random \n",
    "        self.pi /= np.sum(self.pi)\n",
    "        self.A = np.random.rand(self.num_states, self.num_states).astype('float64') # init transition matrix with random \n",
    "        self.A /= np.sum(self.A, 1, keepdims=True)\n",
    "        self.B = np.random.rand(self.num_states, self.num_outputs).astype('float64') # init emission matrix \n",
    "        self.B /= np.sum(self.B, 1, keepdims=True) \n",
    "        \n",
    "    def estimate_with_em(self, sequences, parameters={}, epsilon=0.001, max_iters=100):\n",
    "        # Estimates all parameters not provided in 'parameters' based on 'sequences'.\n",
    "        self.fixed_pi = 'pi' in parameters\n",
    "        self.pi = parameters['pi'] if self.fixed_pi else self.pi \n",
    "        \n",
    "        self.fixed_A = 'A' in parameters\n",
    "        self.A = parameters['A'] if self.fixed_A else self.A\n",
    "        \n",
    "        self.fixed_B = 'B' in parameters\n",
    "        self.B = parameters['B'] if self.fixed_B else self.B\n",
    "           \n",
    "        previous_llh = None # prev log-likelihood\n",
    "        \n",
    "        iteration = 0\n",
    "        while True and iteration < max_iters: # why we dont use for-loop here? \n",
    "            # Infer expected counts.\n",
    "            pi_counts, A_counts, B_counts, log_likelihood = self.e_step(sequences) # E-step from EM-algo\n",
    "\n",
    "            # Update parameters based on counts.\n",
    "            self.m_step(pi_counts, A_counts, B_counts) # M-step from EM-algo\n",
    "\n",
    "            # Output some sequences for debugging.\n",
    "            if iteration % 10 == 0:\n",
    "                self.output(sequences[:10])\n",
    "\n",
    "            # Log likelihood should be increasing\n",
    "            print('iteration %d; log likelihood %.4f' % (iteration, log_likelihood))\n",
    "            if previous_llh:\n",
    "                assert log_likelihood >= previous_llh\n",
    "                if log_likelihood - previous_llh < epsilon:\n",
    "                    break\n",
    "            previous_llh = log_likelihood\n",
    "        \n",
    "            iteration += 1\n",
    "        self.output(sequences[:10])\n",
    "\n",
    "    def e_step(self, sequences):\n",
    "        # Reset counters of statistics\n",
    "        pi_counts = np.zeros_like(self.pi)\n",
    "        A_counts = np.zeros_like(self.A) \n",
    "        B_counts = np.zeros_like(self.B) \n",
    "        total_log_likelihood = 0.0\n",
    "\n",
    "        for sequence in sequences:\n",
    "            # Run Forward-Backward dynamic program\n",
    "            alpha, beta, gamma, xi, log_likelihood = self.forward_backward(sequence)\n",
    "  \n",
    "            # Accumulate statistics.\n",
    "            pi_counts += gamma[:, 0]\n",
    "            A_counts += xi\n",
    "            for t, x in enumerate(sequence):\n",
    "                B_counts[:, x] += gamma[:, t]\n",
    "            \n",
    "            total_log_likelihood += log_likelihood\n",
    "\n",
    "        return pi_counts, A_counts, B_counts, total_log_likelihood\n",
    "\n",
    "    def m_step(self, pi_counts, A_counts, B_counts):\n",
    "        if not self.fixed_pi:\n",
    "            self.pi = pi_counts / np.sum(pi_counts)\n",
    "        if not self.fixed_A:\n",
    "            self.A = A_counts / np.sum(A_counts, 1, keepdims=True)\n",
    "        if not self.fixed_B:\n",
    "            self.B = B_counts / np.sum(B_counts, 1, keepdims=True)\n",
    "        \n",
    "    def max_posterior_decode(self, sequence):\n",
    "        _, _, gamma, _, log_likelihood = self.forward_backward(sequence)\n",
    "        return np.argmax(gamma, 0)\n",
    "        \n",
    "    def forward_backward(self, sequence):\n",
    "        # alpha[i][t] = p(x_1, ..., x_t, z_t = i)\n",
    "        alpha = self.forward(sequence) \n",
    "        \n",
    "        # beta[i][t] = p(x_t+1, ..., x_T|z_t = i)\n",
    "        beta = self.backward(sequence)\n",
    "\n",
    "        # gamma[i][t] = p(z_t = i|x_1, ..., x_T)\n",
    "        ss = np.sum(alpha * beta, 0, dtype=np.float64)\n",
    "        if (ss == 0).any():\n",
    "            print('err')\n",
    "        assert np.isfinite(ss).all()\n",
    "        gamma = (alpha * beta) / ss\n",
    "\n",
    "        # xi[i][j] = p(z_t = i, z_{t+1} = j|x_1, ..., x_T)\n",
    "        xi = np.zeros_like(self.A)\n",
    "        for t in range(1, len(sequence)-1):\n",
    "            this_xi = np.zeros_like(self.A)\n",
    "            for i in range(self.num_states):\n",
    "                for j in range(self.num_states):\n",
    "                    this_xi[i, j] += alpha[i, t] * self.A[i, j] * beta[j, t+1] * self.B[j, sequence[t+1]]        \n",
    "            xi += this_xi / np.sum(this_xi)\n",
    "                \n",
    "        return alpha, beta, gamma, xi, np.log(np.sum(alpha[:, len(sequence)-1]))\n",
    "\n",
    "    def forward(self, sequence):\n",
    "        # alpha[i][t] = p(x_1, ..., x_t, z_t = i)\n",
    "        alpha = np.zeros((len(self.pi), len(sequence)), dtype=np.float64)\n",
    "#         print(alpha.shape)\n",
    "        alpha[:, 0] = self.pi * self.B[:, sequence[0]]\n",
    "        for t in range(len(sequence) - 1):\n",
    "            alpha[:, t + 1] = np.sum(self.A * alpha[:, t], axis=0) * self.B[:, sequence[t+1]]\n",
    "        return alpha \n",
    "    \n",
    "    def backward(self, sequence):\n",
    "        # beta[i][t] = p(x_t+1, ..., x_T|z_t = i)\n",
    "        beta = np.zeros((len(self.pi), len(sequence)), dtype=np.float64)\n",
    "        beta[:, -1] = 1\n",
    "        \n",
    "        for t in range(len(sequence) - 1, 0, -1):\n",
    "            x = sequence[t]\n",
    "            beta[:, t-1] = np.sum(self.A * (beta[:, t] * self.B[:, x])[:, None], axis=1) # check \n",
    "\n",
    "        return beta\n",
    "\n",
    "    def output(self, sequences):\n",
    "        # Output some decoded states. \n",
    "        for i, sequence in enumerate(sequences):\n",
    "            observations = [self.observations_to_char_mapping[x] for x in sequence]                \n",
    "            map_states = [self.states_to_char_mapping[x] for x in self.max_posterior_decode(sequence)]\n",
    "            print('(states):       %s\\n(observations): %s' % (''.join(map_states), ''.join(observations)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 2**: Implement the assertions in 'forward' and 'backward' methods on the HMM class so that the following block passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(states):       uuuu             \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):       s                         \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):                                            \n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):                                            \n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                      eee\n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooo      \n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                                                    \n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 0; log likelihood -6867.7027\n",
      "iteration 1; log likelihood -5090.9216\n",
      "iteration 2; log likelihood -5055.5748\n",
      "iteration 3; log likelihood -5045.1591\n",
      "iteration 4; log likelihood -5042.5737\n",
      "iteration 5; log likelihood -5042.1209\n",
      "iteration 6; log likelihood -5041.8003\n",
      "iteration 7; log likelihood -5041.5297\n",
      "iteration 8; log likelihood -5041.2957\n",
      "iteration 9; log likelihood -5041.0877\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):                                            \n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                                                    \n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 10; log likelihood -5040.8968\n",
      "iteration 11; log likelihood -5040.7156\n",
      "iteration 12; log likelihood -5040.5378\n",
      "iteration 13; log likelihood -5040.3579\n",
      "iteration 14; log likelihood -5040.1705\n",
      "iteration 15; log likelihood -5039.9701\n",
      "iteration 16; log likelihood -5039.7501\n",
      "iteration 17; log likelihood -5039.5031\n",
      "iteration 18; log likelihood -5039.2195\n",
      "iteration 19; log likelihood -5038.8872\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):                                            \n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                  eeeeeee\n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                                                    \n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 20; log likelihood -5038.4898\n",
      "iteration 21; log likelihood -5038.0049\n",
      "iteration 22; log likelihood -5037.4023\n",
      "iteration 23; log likelihood -5036.6447\n",
      "iteration 24; log likelihood -5035.7019\n",
      "iteration 25; log likelihood -5034.5857\n",
      "iteration 26; log likelihood -5033.3874\n",
      "iteration 27; log likelihood -5032.2547\n",
      "iteration 28; log likelihood -5031.3109\n",
      "iteration 29; log likelihood -5030.5992\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):                                            \n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                                                    \n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 30; log likelihood -5030.0817\n",
      "iteration 31; log likelihood -5029.6860\n",
      "iteration 32; log likelihood -5029.3510\n",
      "iteration 33; log likelihood -5029.0408\n",
      "iteration 34; log likelihood -5028.7410\n",
      "iteration 35; log likelihood -5028.4512\n",
      "iteration 36; log likelihood -5028.1787\n",
      "iteration 37; log likelihood -5027.9329\n",
      "iteration 38; log likelihood -5027.7211\n",
      "iteration 39; log likelihood -5027.5457\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                                     eeeeeeeeeeeeeee\n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 40; log likelihood -5027.4049\n",
      "iteration 41; log likelihood -5027.2935\n",
      "iteration 42; log likelihood -5027.2055\n",
      "iteration 43; log likelihood -5027.1356\n",
      "iteration 44; log likelihood -5027.0792\n",
      "iteration 45; log likelihood -5027.0332\n",
      "iteration 46; log likelihood -5026.9949\n",
      "iteration 47; log likelihood -5026.9626\n",
      "iteration 48; log likelihood -5026.9350\n",
      "iteration 49; log likelihood -5026.9111\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                   eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 50; log likelihood -5026.8902\n",
      "iteration 51; log likelihood -5026.8718\n",
      "iteration 52; log likelihood -5026.8554\n",
      "iteration 53; log likelihood -5026.8408\n",
      "iteration 54; log likelihood -5026.8276\n",
      "iteration 55; log likelihood -5026.8157\n",
      "iteration 56; log likelihood -5026.8049\n",
      "iteration 57; log likelihood -5026.7950\n",
      "iteration 58; log likelihood -5026.7861\n",
      "iteration 59; log likelihood -5026.7779\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                  eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 60; log likelihood -5026.7704\n",
      "iteration 61; log likelihood -5026.7635\n",
      "iteration 62; log likelihood -5026.7572\n",
      "iteration 63; log likelihood -5026.7514\n",
      "iteration 64; log likelihood -5026.7461\n",
      "iteration 65; log likelihood -5026.7411\n",
      "iteration 66; log likelihood -5026.7366\n",
      "iteration 67; log likelihood -5026.7324\n",
      "iteration 68; log likelihood -5026.7286\n",
      "iteration 69; log likelihood -5026.7250\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                  eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 70; log likelihood -5026.7217\n",
      "iteration 71; log likelihood -5026.7187\n",
      "iteration 72; log likelihood -5026.7158\n",
      "iteration 73; log likelihood -5026.7132\n",
      "iteration 74; log likelihood -5026.7108\n",
      "iteration 75; log likelihood -5026.7086\n",
      "iteration 76; log likelihood -5026.7065\n",
      "iteration 77; log likelihood -5026.7046\n",
      "iteration 78; log likelihood -5026.7029\n",
      "iteration 79; log likelihood -5026.7012\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                  eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n",
      "iteration 80; log likelihood -5026.6997\n",
      "iteration 81; log likelihood -5026.6983\n",
      "iteration 82; log likelihood -5026.6970\n",
      "iteration 83; log likelihood -5026.6958\n",
      "iteration 84; log likelihood -5026.6947\n",
      "iteration 85; log likelihood -5026.6936\n",
      "iteration 86; log likelihood -5026.6927\n",
      "(states):                        \n",
      "(observations): noeixjtcoxexhwfei\n",
      "(states):                                 \n",
      "(observations): cejjgtjxkhtntjxkegnxiwnxfq\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): gddxiwnxqi thqxgnxbwtxpwhvqnxbwthjqdp\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): nwxoq vqxfqxgixgxefxexjwd gqhxg\n",
      "(states):       eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): wd qhxgixyhecngcqxekdqhxnoeixbwthjqdp\n",
      "(states):                         \n",
      "(observations): nwxfeaqxcwi gngwij\n",
      "(states):                                       \n",
      "(observations): khtntjxvwxnwxbwtxehqxiwnxcejjgtj\n",
      "(states):       oooooooooooo\n",
      "(observations): cejjgtjxgxef\n",
      "(states):                               \n",
      "(observations): khtntjxgxjebxbwtxehqxiwn\n",
      "(states):                  eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "(observations): cejjgtjxthvqxfqxiwxfwhqxgxjoeddxpwhvqnxfbjqdp\n"
     ]
    }
   ],
   "source": [
    "# Since it's a substitution cipher we assume hidden states and observations have same alphabet.\n",
    "state_to_char_mapping = int_to_char_mapping\n",
    "observation_to_char_mapping = int_to_char_mapping\n",
    "\n",
    "# Initialize a HMM with the correct state/output spaces.\n",
    "hmm = HMM(observation_to_char_mapping, state_to_char_mapping)\n",
    "\n",
    "# Estimate the parameters and decode the encrypted sequences.\n",
    "hmm.estimate_with_em(encrypted_sequences[:100], parameters={'pi': pi, 'A': A})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3**: Some of the encrypted sequences are quite long. Try decoding some from 'encrypted/99_encrypted.txt' (note these are in Russian)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 4**: Make your implementation of forward and backward more efficient by removing all but the outermost for-loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5**: Try to classify the author of each text. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
