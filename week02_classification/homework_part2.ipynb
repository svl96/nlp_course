{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary prediction, episode II: make it actually work (4 points)\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a passing grade. Write a short report about what you have tried. More ideas = more bonus points. \n",
    "\n",
    "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know the drill :)\n",
    "\n",
    "You can use either pure __tensorflow__ or __keras__. Feel free to adapt the seminar code for your needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float64')\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data['SalaryNormalized'], bins=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \n",
    "                       \"ContractType\", \"ContractTime\", \"SourceName\"]\n",
    "target_column = \"Log1pSalary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical_columns] = data[categorical_columns].fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing text data\n",
    "Tokenize `Title` and `FullDescription`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data[\"FullDescription\"] = data['FullDescription'].apply(lambda s: ' '.join(tokenizer.tokenize(str(s).lower())))\n",
    "data[\"Title\"] = data['Title'].apply(lambda s: ' '.join(tokenizer.tokenize(str(s).lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlaser\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\vlaser\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import gensim.downloader \n",
    "embeddings = gensim.downloader.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sum(text):\n",
    "    \"\"\"\n",
    "    implement a function that converts preprocessed\n",
    "    comment to a sum of token vectors\n",
    "    \"\"\"\n",
    "    embedding_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "    \n",
    "    for token in text.split(' '):\n",
    "        if token in embeddings.vocab:\n",
    "            features += embeddings.get_vector(token)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data['FullDescriptionEmb'] = data['FullDescription'].apply(lambda text: vectorize_sum(text))\n",
    "# data['TitleEmb'] = data['Title'].apply(lambda text: vectorize_sum(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "               sparse=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = data['Title'].apply(lambda text: vectorize_sum(text))\n",
    "    batch[\"FullDescription\"] = data['FullDescription'].apply(lambda text: vectorize_sum(text))\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_tokens=None, n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
    "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
    "    \n",
    "    l_title = L.Input(shape=[None], name=\"Title\")\n",
    "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
    "    l_categ = L.Input(shape=[n_cat_features], name=\"Categorical\")\n",
    "    \n",
    "#     l_title_emb = L.Embedding(n_tokens, hid_size, name='Title_emb')(l_title)\n",
    "    l_title_conv = L.Convolution1D(filters=64, kernel_size=(3,), name='Title_conv')(l_title)\n",
    "\n",
    "    l_title_pool = L.GlobalMaxPool1D(name='Title_pool')(l_title_conv)\n",
    "    \n",
    "#     l_descr_emb = L.Embedding(n_tokens, hid_size, name='Descr_emb')(l_descr)\n",
    "    l_descr_conv = L.Convolution1D(filters=64, kernel_size=(3,), name='Descr_conv')(l_descr)\n",
    "\n",
    "    l_descr_pool = L.GlobalMaxPool1D(name='Descr_pool')(l_descr_conv)\n",
    "\n",
    "    l_cat_dense = L.Dense(hid_size, name='Categorical_dense')(l_categ)\n",
    "    \n",
    "    l_all = L.Concatenate()([l_title_pool, l_descr_pool, l_cat_dense])\n",
    "    output_layer = L.Dense(1, name='Output_dense')(l_all)\n",
    "\n",
    "    \n",
    "    model = keras.models.Model(inputs=[l_title, l_descr, l_categ], outputs=[output_layer])\n",
    "    model.compile('adam', 'mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer Title_conv: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ecce7de985bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-4b05d7767bd9>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(n_tokens, n_cat_features, hid_size)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#     l_title_emb = L.Embedding(n_tokens, hid_size, name='Title_emb')(l_title)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0ml_title_conv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvolution1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Title_conv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0ml_title_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalMaxPool1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Title_pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_title_conv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer Title_conv: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
    "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
    "assert dummy_pred.shape == (100, 1)\n",
    "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 4            # definitely too small\n",
    "steps_per_epoch = (len(data_train) - 1) // batch_size + 1  # for full pass over data: (len(data_train) - 1) // batch_size + 1\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05), \n",
    "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    \n",
    "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
    "                    validation_steps=data_val.shape[0] // batch_size\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 40000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    engineering systems analyst dorking surrey sal...\n",
       "1    stress engineer glasgow salary **** to **** we...\n",
       "Name: FullDescription, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([data['Title'], data['FullDescription']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_tokenizer.fit_on_texts(np.concatenate([data['Title'], data['FullDescription']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_seq = ker_tokenizer.texts_to_sequences(np.array(data['Title']))\n",
    "descr_seq = ker_tokenizer.texts_to_sequences(np.array(data['FullDescription']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = ker_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(sequences):\n",
    "    max_len = 0\n",
    "    for seq in sequences:\n",
    "        if len(seq) > max_len:\n",
    "            max_len = len(seq)\n",
    "\n",
    "    return pad_sequences(sequences, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_seq = pad_seq(title_seq)\n",
    "descr_seq = pad_seq(descr_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title, val_title, train_descr, val_descr, train_data, val_data = train_test_split(title_seq,\n",
    "                                                                                        descr_seq,\n",
    "                                                                                        data,\n",
    "                                                                                       test_size=0.2,\n",
    "                                                                                       random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((195814, 13), (48954, 13))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200468"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ker_tokenizer.word_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n",
    "\n",
    "`<YOUR_TEXT_HERE>`, i guess..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended options\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `L.BatchNormalization`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time - our `L.GlobalMaxPool1D`\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/). Or use pure tensorflow, it might even be easier :)\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not want to use __`.get_keras_embedding()`__ method for word2vec\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback](https://keras.io/callbacks/#earlystopping).\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "  * Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck! And may the force be with you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
